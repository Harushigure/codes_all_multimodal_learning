{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "from nets.unet import Unet as unet\n",
    "from utils.utils import cvtColor, preprocess_input, resize_image, show_config\n",
    "\n",
    "\n",
    "#--------------------------------------------#\n",
    "#   Two parameters need to be modified when using custom trained models for prediction\n",
    "#   Both model_path and num_classes must be modified!\n",
    "#   If shape mismatch occurs\n",
    "#   Ensure modifications to model_path and num_classes during training are properly addressed\n",
    "#--------------------------------------------#\n",
    "class Unet(object):\n",
    "    _defaults = {\n",
    "        #-------------------------------------------------------------------#\n",
    "        #   model_path points to the weight file in the logs folder\n",
    "        #   Multiple weight files exist in the logs folder after training; select the one with lower validation loss.\n",
    "        #   Lower validation loss does not necessarily indicate higher mIoU, only better generalization on validation set.\n",
    "        #-------------------------------------------------------------------#\n",
    "        \"model_path\"    : 'logs/best_epoch_weights.pth',\n",
    "        #--------------------------------#\n",
    "        #   Number of classes to distinguish + 1\n",
    "        #--------------------------------#\n",
    "        \"num_classes\"   : 2,\n",
    "        #--------------------------------#\n",
    "        #   Backbone network used: vgg, resnet50\n",
    "        #--------------------------------#\n",
    "        \"backbone\"      : \"vgg\",\n",
    "        #--------------------------------#\n",
    "        #   Input image size\n",
    "        #--------------------------------#\n",
    "        \"input_shape\"   : [512, 512],\n",
    "        #-------------------------------------------------#\n",
    "        #   mix_type parameter controls visualization method of detection results\n",
    "        #\n",
    "        #   mix_type = 0: blend original image with generated image\n",
    "        #   mix_type = 1: retain only the generated image\n",
    "        #   mix_type = 2: remove background, retain only target from original image\n",
    "        #-------------------------------------------------#\n",
    "        \"mix_type\"      : 0,\n",
    "        #--------------------------------#\n",
    "        #   Whether to use CUDA\n",
    "        #   Set to False if no GPU available\n",
    "        #--------------------------------#\n",
    "        \"cuda\"          : True,\n",
    "    }\n",
    "\n",
    "    #---------------------------------------------------#\n",
    "    #   Initialize U-Net\n",
    "    #---------------------------------------------------#\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(self._defaults)\n",
    "        for name, value in kwargs.items():\n",
    "            setattr(self, name, value)\n",
    "        #---------------------------------------------------#\n",
    "        #   Set different colors for bounding boxes\n",
    "        #---------------------------------------------------#\n",
    "        if self.num_classes <= 21:\n",
    "            self.colors = [ (0, 0, 0), (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128), (0, 128, 128),\n",
    "                            (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0), (192, 128, 0), (64, 0, 128), (192, 0, 128),\n",
    "                            (64, 128, 128), (192, 128, 128), (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128),\n",
    "                            (128, 64, 12)]\n",
    "        else:\n",
    "            hsv_tuples = [(x / self.num_classes, 1., 1.) for x in range(self.num_classes)]\n",
    "            self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "            self.colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), self.colors))\n",
    "        #---------------------------------------------------#\n",
    "        #   Load model\n",
    "        #---------------------------------------------------#\n",
    "        self.generate()\n",
    "\n",
    "        show_config(**self._defaults)\n",
    "\n",
    "    #---------------------------------------------------#\n",
    "    #   Load all classifications\n",
    "    #---------------------------------------------------#\n",
    "    def generate(self, onnx=False):\n",
    "        self.net = unet(num_classes = self.num_classes, backbone=self.backbone)\n",
    "\n",
    "        device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.net.load_state_dict(torch.load(self.model_path, map_location=device))\n",
    "        self.net    = self.net.eval()\n",
    "        print('{} model, and classes loaded.'.format(self.model_path))\n",
    "        if not onnx:\n",
    "            if self.cuda:\n",
    "                self.net = nn.DataParallel(self.net)\n",
    "                self.net = self.net.cuda()\n",
    "\n",
    "    #---------------------------------------------------#\n",
    "    #   Detect image\n",
    "    #---------------------------------------------------#\n",
    "    def detect_image(self, image, count=False, name_classes=None):\n",
    "        #---------------------------------------------------------#\n",
    "        #   Convert image to RGB to prevent errors during grayscale image prediction.\n",
    "        #   Code only supports RGB image prediction; all other image types are converted to RGB\n",
    "        #---------------------------------------------------------#\n",
    "        image       = cvtColor(image)\n",
    "        #---------------------------------------------------#\n",
    "        #   Create backup of input image for later visualization\n",
    "        #---------------------------------------------------#\n",
    "        old_img     = copy.deepcopy(image)\n",
    "        orininal_h  = np.array(image).shape[0]\n",
    "        orininal_w  = np.array(image).shape[1]\n",
    "        #---------------------------------------------------------#\n",
    "        #   Add gray bars to image for distortion-free resize\n",
    "        #   Alternatively, direct resize can be used for recognition\n",
    "        #---------------------------------------------------------#\n",
    "        image_data, nw, nh  = resize_image(image, (self.input_shape[1],self.input_shape[0]))\n",
    "        #---------------------------------------------------------#\n",
    "        #   Add batch_size dimension\n",
    "        #---------------------------------------------------------#\n",
    "        image_data  = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, np.float32)), (2, 0, 1)), 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(image_data)\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "\n",
    "            #---------------------------------------------------#\n",
    "            #   Pass image through network for prediction\n",
    "            #---------------------------------------------------#\n",
    "            pr = self.net(images)[0]\n",
    "            #---------------------------------------------------#\n",
    "            #   Extract class for each pixel\n",
    "            #---------------------------------------------------#\n",
    "            pr = F.softmax(pr.permute(1,2,0),dim = -1).cpu().numpy()\n",
    "            #--------------------------------------#\n",
    "            #   Remove gray bar regions\n",
    "            #--------------------------------------#\n",
    "            pr = pr[int((self.input_shape[0] - nh) // 2) : int((self.input_shape[0] - nh) // 2 + nh), \\\n",
    "                    int((self.input_shape[1] - nw) // 2) : int((self.input_shape[1] - nw) // 2 + nw)]\n",
    "            #---------------------------------------------------#\n",
    "            #   Resize image\n",
    "            #---------------------------------------------------#\n",
    "            pr = cv2.resize(pr, (orininal_w, orininal_h), interpolation = cv2.INTER_LINEAR)\n",
    "            #---------------------------------------------------#\n",
    "            #   Extract class for each pixel\n",
    "            #---------------------------------------------------#\n",
    "            pr = pr.argmax(axis=-1)\n",
    "\n",
    "        #---------------------------------------------------------#\n",
    "        #   Count pixels\n",
    "        #---------------------------------------------------------#\n",
    "        if count:\n",
    "            classes_nums        = np.zeros([self.num_classes])\n",
    "            total_points_num    = orininal_h * orininal_w\n",
    "            print('-' * 63)\n",
    "            print(\"|%25s | %15s | %15s|\"%(\"Key\", \"Value\", \"Ratio\"))\n",
    "            print('-' * 63)\n",
    "            for i in range(self.num_classes):\n",
    "                num     = np.sum(pr == i)\n",
    "                ratio   = num / total_points_num * 100\n",
    "                if num > 0:\n",
    "                    print(\"|%25s | %15s | %14.2f%%|\"%(str(name_classes[i]), str(num), ratio))\n",
    "                    print('-' * 63)\n",
    "                classes_nums[i] = num\n",
    "            print(\"classes_nums:\", classes_nums)\n",
    "\n",
    "        if self.mix_type == 0:\n",
    "            # seg_img = np.zeros((np.shape(pr)[0], np.shape(pr)[1], 3))\n",
    "            # for c in range(self.num_classes):\n",
    "            #     seg_img[:, :, 0] += ((pr[:, :] == c ) * self.colors[c][0]).astype('uint8')\n",
    "            #     seg_img[:, :, 1] += ((pr[:, :] == c ) * self.colors[c][1]).astype('uint8')\n",
    "            #     seg_img[:, :, 2] += ((pr[:, :] == c ) * self.colors[c][2]).astype('uint8')\n",
    "            seg_img = np.reshape(np.array(self.colors, np.uint8)[np.reshape(pr, [-1])], [orininal_h, orininal_w, -1])\n",
    "            #------------------------------------------------#\n",
    "            #   Convert new image to PIL Image format\n",
    "            #------------------------------------------------#\n",
    "            image   = Image.fromarray(np.uint8(seg_img))\n",
    "            #------------------------------------------------#\n",
    "            #   Blend new image with original image\n",
    "            #------------------------------------------------#\n",
    "            # image   = Image.blend(old_img, image, 0.5)\n",
    "\n",
    "        elif self.mix_type == 1:\n",
    "            # seg_img = np.zeros((np.shape(pr)[0], np.shape(pr)[1], 3))\n",
    "            # for c in range(self.num_classes):\n",
    "            #     seg_img[:, :, 0] += ((pr[:, :] == c ) * self.colors[c][0]).astype('uint8')\n",
    "            #     seg_img[:, :, 1] += ((pr[:, :] == c ) * self.colors[c][1]).astype('uint8')\n",
    "            #     seg_img[:, :, 2] += ((pr[:, :] == c ) * self.colors[c][2]).astype('uint8')\n",
    "            seg_img = np.reshape(np.array(self.colors, np.uint8)[np.reshape(pr, [-1])], [orininal_h, orininal_w, -1])\n",
    "            #------------------------------------------------#\n",
    "            #   Convert new image to PIL Image format\n",
    "            #------------------------------------------------#\n",
    "            image   = Image.fromarray(np.uint8(seg_img))\n",
    "\n",
    "        elif self.mix_type == 2:\n",
    "            seg_img = (np.expand_dims(pr != 0, -1) * np.array(old_img, np.float32)).astype('uint8')\n",
    "            #------------------------------------------------#\n",
    "            #   Convert new image to PIL Image format\n",
    "            #------------------------------------------------#\n",
    "            image = Image.fromarray(np.uint8(seg_img))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def get_FPS(self, image, test_interval):\n",
    "        #---------------------------------------------------------#\n",
    "        #   Convert image to RGB to prevent errors during grayscale image prediction.\n",
    "        #   Code only supports RGB image prediction; all other image types are converted to RGB\n",
    "        #---------------------------------------------------------#\n",
    "        image       = cvtColor(image)\n",
    "        #---------------------------------------------------------#\n",
    "        #   Add gray bars to image for distortion-free resize\n",
    "        #   Alternatively, direct resize can be used for recognition\n",
    "        #---------------------------------------------------------#\n",
    "        image_data, nw, nh  = resize_image(image, (self.input_shape[1],self.input_shape[0]))\n",
    "        #---------------------------------------------------------#\n",
    "        #   Add batch_size dimension\n",
    "        #---------------------------------------------------------#\n",
    "        image_data  = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, np.float32)), (2, 0, 1)), 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(image_data)\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "\n",
    "            #---------------------------------------------------#\n",
    "            #   Pass image through network for prediction\n",
    "            #---------------------------------------------------#\n",
    "            pr = self.net(images)[0]\n",
    "            #---------------------------------------------------#\n",
    "            #   Extract class for each pixel\n",
    "            #---------------------------------------------------#\n",
    "            pr = F.softmax(pr.permute(1,2,0),dim = -1).cpu().numpy().argmax(axis=-1)\n",
    "            #--------------------------------------#\n",
    "            #   Remove gray bar regions\n",
    "            #--------------------------------------#\n",
    "            pr = pr[int((self.input_shape[0] - nh) // 2) : int((self.input_shape[0] - nh) // 2 + nh), \\\n",
    "                    int((self.input_shape[1] - nw) // 2) : int((self.input_shape[1] - nw) // 2 + nw)]\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(test_interval):\n",
    "            with torch.no_grad():\n",
    "                #---------------------------------------------------#\n",
    "                #   Pass image through network for prediction\n",
    "                #---------------------------------------------------#\n",
    "                pr = self.net(images)[0]\n",
    "                #---------------------------------------------------#\n",
    "                #   Extract class for each pixel\n",
    "                #---------------------------------------------------#\n",
    "                pr = F.softmax(pr.permute(1,2,0),dim = -1).cpu().numpy().argmax(axis=-1)\n",
    "                #--------------------------------------#\n",
    "                #   Remove gray bar regions\n",
    "                #--------------------------------------#\n",
    "                pr = pr[int((self.input_shape[0] - nh) // 2) : int((self.input_shape[0] - nh) // 2 + nh), \\\n",
    "                        int((self.input_shape[1] - nw) // 2) : int((self.input_shape[1] - nw) // 2 + nw)]\n",
    "        t2 = time.time()\n",
    "        tact_time = (t2 - t1) / test_interval\n",
    "        return tact_time\n",
    "\n",
    "    def convert_to_onnx(self, simplify, model_path):\n",
    "        import onnx\n",
    "        self.generate(onnx=True)\n",
    "\n",
    "        im                  = torch.zeros(1, 3, *self.input_shape).to('cpu')  # image size(1, 3, 512, 512) BCHW\n",
    "        input_layer_names   = [\"images\"]\n",
    "        output_layer_names  = [\"output\"]\n",
    "\n",
    "        # Export the model\n",
    "        print(f'Starting export with onnx {onnx.__version__}.')\n",
    "        torch.onnx.export(self.net,\n",
    "                        im,\n",
    "                        f               = model_path,\n",
    "                        verbose         = False,\n",
    "                        opset_version   = 12,\n",
    "                        training        = torch.onnx.TrainingMode.EVAL,\n",
    "                        do_constant_folding = True,\n",
    "                        input_names     = input_layer_names,\n",
    "                        output_names    = output_layer_names,\n",
    "                        dynamic_axes    = None)\n",
    "\n",
    "        # Checks\n",
    "        model_onnx = onnx.load(model_path)  # load onnx model\n",
    "        onnx.checker.check_model(model_onnx)  # check onnx model\n",
    "\n",
    "        # Simplify onnx\n",
    "        if simplify:\n",
    "            import onnxsim\n",
    "            print(f'Simplifying with onnx-simplifier {onnxsim.__version__}.')\n",
    "            model_onnx, check = onnxsim.simplify(\n",
    "                model_onnx,\n",
    "                dynamic_input_shape=False,\n",
    "                input_shapes=None)\n",
    "            assert check, 'assert check failed'\n",
    "            onnx.save(model_onnx, model_path)\n",
    "\n",
    "        print('Onnx model save as {}'.format(model_path))\n",
    "\n",
    "    def get_miou_png(self, image):\n",
    "        #---------------------------------------------------------#\n",
    "        #   Convert image to RGB to prevent errors during grayscale image prediction.\n",
    "        #   Code only supports RGB image prediction; all other image types are converted to RGB\n",
    "        #---------------------------------------------------------#\n",
    "        image       = cvtColor(image)\n",
    "        orininal_h  = np.array(image).shape[0]\n",
    "        orininal_w  = np.array(image).shape[1]\n",
    "        #---------------------------------------------------------#\n",
    "        #   Add gray bars to image for distortion-free resize\n",
    "        #   Alternatively, direct resize can be used for recognition\n",
    "        #---------------------------------------------------------#\n",
    "        image_data, nw, nh  = resize_image(image, (self.input_shape[1],self.input_shape[0]))\n",
    "        #---------------------------------------------------------#\n",
    "        #   Add batch_size dimension\n",
    "        #---------------------------------------------------------#\n",
    "        image_data  = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, np.float32)), (2, 0, 1)), 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(image_data)\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "\n",
    "            #---------------------------------------------------#\n",
    "            #   Pass image through network for prediction\n",
    "            #---------------------------------------------------#\n",
    "            pr = self.net(images)[0]\n",
    "            #---------------------------------------------------#\n",
    "            #   Extract class for each pixel\n",
    "            #---------------------------------------------------#\n",
    "            pr = F.softmax(pr.permute(1,2,0),dim = -1).cpu().numpy()\n",
    "            #--------------------------------------#\n",
    "            #   Remove gray bar regions\n",
    "            #--------------------------------------#\n",
    "            pr = pr[int((self.input_shape[0] - nh) // 2) : int((self.input_shape[0] - nh) // 2 + nh), \\\n",
    "                    int((self.input_shape[1] - nw) // 2) : int((self.input_shape[1] - nw) // 2 + nw)]\n",
    "            #---------------------------------------------------#\n",
    "            #   Resize image\n",
    "            #---------------------------------------------------#\n",
    "            pr = cv2.resize(pr, (orininal_w, orininal_h), interpolation = cv2.INTER_LINEAR)\n",
    "            #---------------------------------------------------#\n",
    "            #   Extract class for each pixel\n",
    "            #---------------------------------------------------#\n",
    "            pr = pr.argmax(axis=-1)\n",
    "\n",
    "        image = Image.fromarray(np.uint8(pr))\n",
    "        return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
