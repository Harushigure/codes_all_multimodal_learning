{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pip install torch torchvision\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import re  # Import regular expression module for extracting numbers\n",
    "\n",
    "\n",
    "# Load pretrained VGG-19 model and define custom network\n",
    "class VGG19Extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19Extractor, self).__init__()\n",
    "        vgg19 = models.vgg19(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(vgg19.features.children())[:26])  # Extract up to conv5_1\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d((1, 1))  # Adaptive max pooling to 1x1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # Extract conv5_1 output\n",
    "        x = self.max_pool(x)  # Max pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten to 1D vector\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define image preprocessing function\n",
    "def preprocess_image(image_path, device):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize image to 224x224\n",
    "        transforms.ToTensor(),  # Convert to Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')  # Open image and convert to RGB format\n",
    "    input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return input_tensor.to(device)  # Move input tensor to specified device\n",
    "\n",
    "\n",
    "# Sort filenames in numerical order\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "\n",
    "# Batch process images in folder\n",
    "def process_images_in_folder(folder_path, model, device):\n",
    "    features_list = []  # Store features for each image\n",
    "\n",
    "    # Get file list and sort in numerical order\n",
    "    filenames = sorted_alphanumeric(os.listdir(folder_path))\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Process only image files\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                # Preprocess image\n",
    "                input_tensor = preprocess_image(image_path, device)\n",
    "\n",
    "                # Extract features using model\n",
    "                with torch.no_grad():  # Disable gradient computation to save memory\n",
    "                    features = model(input_tensor)\n",
    "\n",
    "                # Convert features to numpy array and store\n",
    "                features_numpy = features.squeeze().cpu().numpy()  # Move back to CPU and convert to NumPy array\n",
    "                features_list.append(features_numpy)\n",
    "\n",
    "                print(f\"Processed: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "    return features_list\n",
    "\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "    # Folder path\n",
    "    folder_path = \"C:/Users/12152/Desktop/data/sepia4/vision_white_after/segmentation_histogram_equalization_test\"  # Replace with your image folder path\n",
    "\n",
    "    # Detect device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create model instance and move to specified device\n",
    "    model = VGG19Extractor().to(device)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Batch process images\n",
    "    features_list = process_images_in_folder(folder_path, model, device)\n",
    "\n",
    "    # Convert feature list to NumPy array\n",
    "    features_array = np.array(features_list)  # Shape: (N, 512), where N is the number of images\n",
    "\n",
    "    # Save as .npy file\n",
    "    np.save(\"C:/Users/12152/Desktop/data/sepia4/vision_white_after/segmentation_histogram_equalization_test/features.npy\", features_array)\n",
    "    print(\"Features saved to 'features.npy'\")\n",
    "\n",
    "    # Output features (can be saved to file or processed further)\n",
    "    if features_list:\n",
    "        print(\"Feature extraction completed. Number of images processed:\", len(features_list))\n",
    "    else:\n",
    "        print(\"No images were processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
